{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b99d029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: False\n",
      "torch version: 2.1.0\n",
      "numpy version: 1.26.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5fc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d644af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174f1eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3, 4, 5, 6]).reshape((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d39fcf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 32 artists>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 32\n",
    "d = Dirichlet(torch.tensor([10*1/N] * N))\n",
    "s = d.sample()\n",
    "s, s.sum()\n",
    "plt.bar(list(range(len(s))), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c49bdd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1],\n",
       "          [2]],\n",
       " \n",
       "         [[3],\n",
       "          [4]]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " torch.Size([2, 2, 1]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[[1], [2]], [[3], [4]]])\n",
    "t, t.flatten(1), t.size(), t.flatten(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68f6121f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2786e-01,  9.2719e-01],\n",
       "        [ 3.7353e-01, -1.0000e+32]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones((2,2), dtype=torch.bool)\n",
    "mask[1, 1] = False\n",
    "t = torch.randn((2,2))\n",
    "t.where(mask, torch.full_like(t, -1e32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edae5726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros((11, 11, 10))\n",
    "t[0] = 1 # torch.ones((11, 10))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f572fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 26421880/26421880 [00:01<00:00, 16810965.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 2541102.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4422102/4422102 [00:00<00:00, 23921758.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 13345041.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bec049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ae1c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a12d0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "094703dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f38761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f552b562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298630  [   64/60000]\n",
      "loss: 2.290707  [ 6464/60000]\n",
      "loss: 2.263347  [12864/60000]\n",
      "loss: 2.267030  [19264/60000]\n",
      "loss: 2.242172  [25664/60000]\n",
      "loss: 2.215843  [32064/60000]\n",
      "loss: 2.233211  [38464/60000]\n",
      "loss: 2.187733  [44864/60000]\n",
      "loss: 2.192698  [51264/60000]\n",
      "loss: 2.168803  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 2.149618 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.154451  [   64/60000]\n",
      "loss: 2.150555  [ 6464/60000]\n",
      "loss: 2.084796  [12864/60000]\n",
      "loss: 2.108788  [19264/60000]\n",
      "loss: 2.047787  [25664/60000]\n",
      "loss: 1.991063  [32064/60000]\n",
      "loss: 2.035543  [38464/60000]\n",
      "loss: 1.940731  [44864/60000]\n",
      "loss: 1.953674  [51264/60000]\n",
      "loss: 1.891864  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 1.872838 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.896520  [   64/60000]\n",
      "loss: 1.878752  [ 6464/60000]\n",
      "loss: 1.745619  [12864/60000]\n",
      "loss: 1.799116  [19264/60000]\n",
      "loss: 1.683786  [25664/60000]\n",
      "loss: 1.638151  [32064/60000]\n",
      "loss: 1.681358  [38464/60000]\n",
      "loss: 1.565551  [44864/60000]\n",
      "loss: 1.600933  [51264/60000]\n",
      "loss: 1.509459  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.508196 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.563071  [   64/60000]\n",
      "loss: 1.547206  [ 6464/60000]\n",
      "loss: 1.380916  [12864/60000]\n",
      "loss: 1.464710  [19264/60000]\n",
      "loss: 1.344837  [25664/60000]\n",
      "loss: 1.341265  [32064/60000]\n",
      "loss: 1.374171  [38464/60000]\n",
      "loss: 1.282651  [44864/60000]\n",
      "loss: 1.327332  [51264/60000]\n",
      "loss: 1.237008  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.249387 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.313211  [   64/60000]\n",
      "loss: 1.317784  [ 6464/60000]\n",
      "loss: 1.138728  [12864/60000]\n",
      "loss: 1.250865  [19264/60000]\n",
      "loss: 1.124152  [25664/60000]\n",
      "loss: 1.150946  [32064/60000]\n",
      "loss: 1.186431  [38464/60000]\n",
      "loss: 1.108506  [44864/60000]\n",
      "loss: 1.156770  [51264/60000]\n",
      "loss: 1.078906  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.089471 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4204f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4028d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
